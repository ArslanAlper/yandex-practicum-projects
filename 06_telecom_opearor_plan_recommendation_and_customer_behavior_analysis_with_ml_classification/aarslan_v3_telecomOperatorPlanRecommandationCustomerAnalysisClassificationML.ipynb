{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Intro Project - Telecom Users Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Project-Description\" data-toc-modified-id=\"Project-Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Project Description</a></span></li><li><span><a href=\"#Opening-and-looking-through-the-data-file\" data-toc-modified-id=\"Opening-and-looking-through-the-data-file-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Opening and looking through the data file</a></span></li><li><span><a href=\"#Splitting-the-source-data\" data-toc-modified-id=\"Splitting-the-source-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Splitting the source data</a></span></li><li><span><a href=\"#Studying-the-models\" data-toc-modified-id=\"Studying-the-models-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Studying the models</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree-Classifier\" data-toc-modified-id=\"Decision-Tree-Classifier-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Decision Tree Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decision-Tree-Model-without-Hyperparameter-Optimisation\" data-toc-modified-id=\"Decision-Tree-Model-without-Hyperparameter-Optimisation-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Decision Tree Model without Hyperparameter Optimisation</a></span><ul class=\"toc-item\"><li><span><a href=\"#accuracy-scores-with-'accuracy_score'-method\" data-toc-modified-id=\"accuracy-scores-with-'accuracy_score'-method-4.1.1.1\"><span class=\"toc-item-num\">4.1.1.1&nbsp;&nbsp;</span>accuracy scores with 'accuracy_score' method</a></span></li><li><span><a href=\"#accuracy_scores-with-'scores'-method\" data-toc-modified-id=\"accuracy_scores-with-'scores'-method-4.1.1.2\"><span class=\"toc-item-num\">4.1.1.2&nbsp;&nbsp;</span>accuracy_scores with 'scores' method</a></span></li></ul></li><li><span><a href=\"#Manual-Hyperparameter-Tuning\" data-toc-modified-id=\"Manual-Hyperparameter-Tuning-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Manual Hyperparameter Tuning</a></span></li><li><span><a href=\"#Grid-Search-Optimisation\" data-toc-modified-id=\"Grid-Search-Optimisation-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Grid Search Optimisation</a></span></li><li><span><a href=\"#Random-Search-Optimisation\" data-toc-modified-id=\"Random-Search-Optimisation-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Random Search Optimisation</a></span></li></ul></li><li><span><a href=\"#Random-Forest-Classifier\" data-toc-modified-id=\"Random-Forest-Classifier-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Random Forest Classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest-Model-without-Hyperparameter-Optimisation\" data-toc-modified-id=\"Random-Forest-Model-without-Hyperparameter-Optimisation-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Random Forest Model without Hyperparameter Optimisation</a></span></li><li><span><a href=\"#Manual-Hyperparameter-Tuning\" data-toc-modified-id=\"Manual-Hyperparameter-Tuning-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Manual Hyperparameter Tuning</a></span></li><li><span><a href=\"#Grid-Search-Optimisation\" data-toc-modified-id=\"Grid-Search-Optimisation-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>Grid Search Optimisation</a></span></li><li><span><a href=\"#Random-Search-Optimisation\" data-toc-modified-id=\"Random-Search-Optimisation-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>Random Search Optimisation</a></span></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression-Model-without-Hyperparameter-Optimisation\" data-toc-modified-id=\"Logistic-Regression-Model-without-Hyperparameter-Optimisation-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Logistic Regression Model without Hyperparameter Optimisation</a></span></li><li><span><a href=\"#Manual-Hyperparameter-Optimisation\" data-toc-modified-id=\"Manual-Hyperparameter-Optimisation-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Manual Hyperparameter Optimisation</a></span></li><li><span><a href=\"#Grid-Search-Optimisation\" data-toc-modified-id=\"Grid-Search-Optimisation-4.3.3\"><span class=\"toc-item-num\">4.3.3&nbsp;&nbsp;</span>Grid Search Optimisation</a></span></li></ul></li></ul></li><li><span><a href=\"#Checking-the-quality-of-the-model\" data-toc-modified-id=\"Checking-the-quality-of-the-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Checking the quality of the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Sanity-Check\" data-toc-modified-id=\"Sanity-Check-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Sanity Check</a></span></li><li><span><a href=\"#Test-Accuracy-Score\" data-toc-modified-id=\"Test-Accuracy-Score-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Test Accuracy Score</a></span></li><li><span><a href=\"#Checking-the-False-Predictions'-Ratio\" data-toc-modified-id=\"Checking-the-False-Predictions'-Ratio-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Checking the False Predictions' Ratio</a></span></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Confusion Matrix</a></span></li><li><span><a href=\"#Precision-Score\" data-toc-modified-id=\"Precision-Score-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Precision Score</a></span></li><li><span><a href=\"#Recall-Score\" data-toc-modified-id=\"Recall-Score-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Recall Score</a></span></li><li><span><a href=\"#f1-Score\" data-toc-modified-id=\"f1-Score-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>f1 Score</a></span></li></ul></li><li><span><a href=\"#General-Conclusion\" data-toc-modified-id=\"General-Conclusion-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>General Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "We have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, we need to develop a model that will pick the right plan. Since weâ€™ve already performed the data preprocessing step, we can move straight to creating the model.\n",
    "\n",
    "We will develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. We will check the accuracy using the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and looking through the data file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will take a general look to examine the dataset. First we will import standart libraries, read the csv file, and briefly recognize and describe the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_behavior = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_behavior.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3209</td>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3210</td>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3211</td>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3212</td>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3213</td>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_behavior.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are 4 numeric feature variables and 1 categorical target variable, 'is_ultra'.\n",
    "- Let's look at the observations in order and try to make a classification ourselves, our aim is to understand how the model will think, or to see how we will think like a model.\n",
    "- When we compare the 3rd index which class equal to '1' to the previous indexes whic classes are '0', it seems like the most important features are 'calls' and 'minutes'. Normally it's expected that internet usage has positive effect to determine the class, but there are negative relation in the first 4 observations.\n",
    "- When we look at the last 3 observations in the tail table, although the 'calls' and 'minutes' values of 3211th row are bigger and 'mb_used' value of the same row is smaller than the relationed values of the last row, the classsification is different from our first evaluation.\n",
    "- It's too hard for us to predict the classes of plans from the features. This is why we need the machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "users_behavior.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>calls</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>63.038892</td>\n",
       "      <td>33.236368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>62.000</td>\n",
       "      <td>82.0000</td>\n",
       "      <td>244.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>minutes</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>0.0</td>\n",
       "      <td>274.5750</td>\n",
       "      <td>430.600</td>\n",
       "      <td>571.9275</td>\n",
       "      <td>1632.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>messages</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>30.000</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>224.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mb_used</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>17207.673836</td>\n",
       "      <td>7570.968246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12491.9025</td>\n",
       "      <td>16943.235</td>\n",
       "      <td>21424.7000</td>\n",
       "      <td>49745.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is_ultra</td>\n",
       "      <td>3214.0</td>\n",
       "      <td>0.306472</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean          std  min         25%        50%  \\\n",
       "calls     3214.0     63.038892    33.236368  0.0     40.0000     62.000   \n",
       "minutes   3214.0    438.208787   234.569872  0.0    274.5750    430.600   \n",
       "messages  3214.0     38.281269    36.148326  0.0      9.0000     30.000   \n",
       "mb_used   3214.0  17207.673836  7570.968246  0.0  12491.9025  16943.235   \n",
       "is_ultra  3214.0      0.306472     0.461100  0.0      0.0000      0.000   \n",
       "\n",
       "                 75%       max  \n",
       "calls        82.0000    244.00  \n",
       "minutes     571.9275   1632.06  \n",
       "messages     57.0000    224.00  \n",
       "mb_used   21424.7000  49745.73  \n",
       "is_ultra      1.0000      1.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_behavior.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data types are normal. We will look at the target variable, 'is_ultra'. How many 'ultra' plan users are there in dataset? We will look for just a general information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_behavior['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "users_behavior['is_ultra'].value_counts(normalize=True).plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 Ultra vs. 7 Smart for 10 customers.\n",
    "- All data types are normal, there aren't any data preprocessing requirement.\n",
    "- There aren't any missing values, and we assume that there aren't any outliers.\n",
    "- We can go ahead to creating the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the source data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to separate the dataset into 3 parts, sets for training - validation - test.\n",
    "- We will use the training set to train our model.\n",
    "- We will use the validation set to compare the validation results to the training results to find the accuracy scores and to control overfitting or underfitting.\n",
    "- We will use the test set for the last check.\n",
    "- First, we will split the dataset into 2 parts. One will be for 'training' (60% of the source data), the other part (40% of the source data) will be splitted into equal parts (50%-50%) for 'validation' (%20 of source) and 'test' (%20 source) after the first split.\n",
    "- We need the 'train_test_split' method from the sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_and_validation_data = train_test_split(users_behavior, test_size=0.40, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1286, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_and_validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will split the test_and_validation_data into equal two parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, validation_data = train_test_split(test_and_validation_data, test_size=0.50, random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(643, 5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we splitted the source data into 3 parts with the ratios of 60%-20%-20%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the features and target for the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = train_data.drop(['is_ultra'], axis=1)\n",
    "target_train = train_data['is_ultra']\n",
    "\n",
    "features_valid = validation_data.drop(['is_ultra'], axis=1)\n",
    "target_valid = validation_data['is_ultra']\n",
    "\n",
    "features_test = test_data.drop(['is_ultra'], axis=1)\n",
    "target_test = test_data['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'is_ultra' is our target variable. We need to define a customer's behavior accordance with the calls, minutes, messages and internet usages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studying the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will study on the the 3 main classifier models. First we need to import them from the sklearn library, and we also need to import accuracy_score from sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we will create a model from classes for each algorithm. Then we will fit our model with training data without hyperparameter tuning and after that, we will predict the results using validation data. At the last, we will compare the model scores of the training data and validation data.\n",
    "- We will change some hyperparameters in some for loops for some hyperparameters. We need to tune the hyperparameters during model evaluation and first we will make it manually. We will observe the scores of each model, and difference of scores for training and validation sets to see overfitting and underfitting.\n",
    "- If the training scores too higher than the validation scores, we will evaluate them as overfitting.\n",
    "- If the scores are close but below 0.75 which is the project requirement, we will evaluate them as underfitting.\n",
    "- We need to find the optimum score and also find the minimum difference of training and validation sets to avoid overfitting or underfitting.\n",
    "- At the last, we will use Grid Search and Random Search Optimisation Methods to find the best values of hyperparameters.\n",
    "- We will use the '88' for random_state hyperparameter for all models to define random pseudo numbers.\n",
    "- We will make this steps for all 3 algorithms and find the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Model without Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will create a Decision Tree model, then we will train the tree model with fit method using training dataset, at the last we will check the scores of training and validation sets. We will use first accuracy method, then score method to find the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### accuracy scores with 'accuracy_score' method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to find predictions before using the 'accuracy_score' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = tree.predict(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_valid = tree.predict(features_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train = accuracy_score(target_train, predictions_train)\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200622083981337"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_valid = accuracy_score(target_valid, predictions_valid)\n",
    "accuracy_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### accuracy_scores with 'scores' method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can find the scores without finding the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = tree.score(features_train, target_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7200622083981337"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = tree.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The accuracy_score shows us the percentage of correct predictions. \n",
    "- Our first model accurately predicted all training features classes as it had encountered them before, but failed in guessing the validation set. There is barely overfitting.\n",
    "- We have tried 2 methods to find accuracy scores. The second is the easiest method. We will use the second after that.\n",
    "- We need to find the closest train and validation scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will analyze 'max_depth', 'min_samples_split', 'min_samples_leaf' and 'max_features' in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : [0.7479253112033195, 0.7713841368584758, -0.023458825655156335]\n",
      "max_depth = 2 : [0.7795643153526971, 0.7978227060653188, -0.018258390712621697]\n",
      "max_depth = 3 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 4 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 5 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 6 : [0.8303941908713693, 0.7947122861586314, 0.03568190471273791]\n",
      "max_depth = 7 : [0.8423236514522822, 0.80248833592535, 0.0398353155269322]\n",
      "max_depth = 8 : [0.8609958506224067, 0.7947122861586314, 0.06628356446377526]\n",
      "max_depth = 9 : [0.8687759336099585, 0.7947122861586314, 0.0740636474513271]\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 10):\n",
    "    tree = DecisionTreeClassifier(random_state=88, max_depth=depth)\n",
    "    tree.fit(features_train, target_train)\n",
    "    train_score = tree.score(features_train, target_train)\n",
    "    valid_score = tree.score(features_valid, target_valid)\n",
    "    scores_difference = train_score - valid_score\n",
    "    scores = [train_score, valid_score, scores_difference]\n",
    "    print(\"max_depth =\", depth, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have tried all int numbers between 1 and 10 for max_depth hyperparameter. \n",
    "- The higher the max_depth, the higher the scores. But we need to find the optimum value. \n",
    "- The differences between scores of training sets and validation sets are on the right. We subtracted the validation set score from the score of the training set. The closest scores means the optimum max_depth option for our model. The best option is 4 for this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_split = 2 : [1.0, 0.7200622083981337, 0.27993779160186627]\n",
      "min_samples_split = 12 : [0.9050829875518672, 0.7356143079315708, 0.16946867962029644]\n",
      "min_samples_split = 22 : [0.870850622406639, 0.7682737169517885, 0.10257690545485054]\n",
      "min_samples_split = 32 : [0.8485477178423236, 0.7791601866251944, 0.06938753121712926]\n",
      "min_samples_split = 42 : [0.8412863070539419, 0.7916018662519441, 0.04968444080199785]\n",
      "min_samples_split = 52 : [0.8335062240663901, 0.7931570762052877, 0.04034914786110233]\n",
      "min_samples_split = 62 : [0.828838174273859, 0.7993779160186625, 0.029460258255196492]\n",
      "min_samples_split = 72 : [0.8262448132780082, 0.7978227060653188, 0.02842210721268945]\n",
      "min_samples_split = 82 : [0.8158713692946058, 0.8040435458786936, 0.011827823415912153]\n",
      "min_samples_split = 92 : [0.8158713692946058, 0.8040435458786936, 0.011827823415912153]\n",
      "min_samples_split = 102 : [0.8158713692946058, 0.8040435458786936, 0.011827823415912153]\n"
     ]
    }
   ],
   "source": [
    "for split in range(2, 105, 10):\n",
    "    tree = DecisionTreeClassifier(random_state=88, min_samples_split=split)\n",
    "    tree.fit(features_train, target_train)\n",
    "    train_score = tree.score(features_train, target_train)\n",
    "    valid_score = tree.score(features_valid, target_valid)\n",
    "    scores_difference = train_score - valid_score\n",
    "    scores = [train_score, valid_score, scores_difference]\n",
    "    print(\"min_samples_split =\", split, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores of training sets decrease and the scores of validation sets increase while 'min_samples_split' hyperparameters increase. After value of 82 for 'min_samples_split', the scores are fixed and the differences of scores are minimized. The best option for 'min_samples_split' is between 72 and 82."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples_leaf = 1 : [1.0, 0.7200622083981337, 0.27993779160186627]\n",
      "min_samples_leaf = 11 : [0.8397302904564315, 0.7791601866251944, 0.060570103831237176]\n",
      "min_samples_leaf = 21 : [0.8153526970954357, 0.7527216174183515, 0.06263107967708414]\n",
      "min_samples_leaf = 31 : [0.8065352697095436, 0.7807153965785381, 0.025819873131005533]\n",
      "min_samples_leaf = 41 : [0.7992738589211619, 0.7931570762052877, 0.006116782715874125]\n",
      "min_samples_leaf = 51 : [0.7956431535269709, 0.7962674961119751, -0.0006243425850042117]\n",
      "min_samples_leaf = 61 : [0.7940871369294605, 0.8087091757387247, -0.01462203880926416]\n",
      "min_samples_leaf = 71 : [0.7816390041493776, 0.80248833592535, -0.02084933177597237]\n",
      "min_samples_leaf = 81 : [0.7816390041493776, 0.80248833592535, -0.02084933177597237]\n",
      "min_samples_leaf = 91 : [0.7816390041493776, 0.80248833592535, -0.02084933177597237]\n"
     ]
    }
   ],
   "source": [
    "for leaf in range(1, 100, 10):\n",
    "    tree = DecisionTreeClassifier(random_state=88, min_samples_leaf=leaf)\n",
    "    tree.fit(features_train, target_train)\n",
    "    train_score = tree.score(features_train, target_train)\n",
    "    valid_score = tree.score(features_valid, target_valid)\n",
    "    scores_difference = train_score - valid_score\n",
    "    scores = [train_score, valid_score, scores_difference]\n",
    "    print(\"min_samples_leaf =\", leaf, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Until 71, the training scores decrease. After this value score is fixed for training dataset.\n",
    "- Until 21, the validation scores decrease, after that it increases until 71. Then it is fixed for validation score.\n",
    "- The difference of scores is minimized at 41. The best option for 'min_samples_leaf' is between 41 and 51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_features = 0.1 : [1.0, 0.7216174183514774, 0.2783825816485226]\n",
      "max_features = 0.2 : [1.0, 0.7216174183514774, 0.2783825816485226]\n",
      "max_features = 0.3 : [1.0, 0.7216174183514774, 0.2783825816485226]\n",
      "max_features = 0.4 : [1.0, 0.7216174183514774, 0.2783825816485226]\n",
      "max_features = 0.5 : [1.0, 0.7387247278382582, 0.26127527216174184]\n",
      "max_features = 0.6 : [1.0, 0.7387247278382582, 0.26127527216174184]\n",
      "max_features = 0.7 : [1.0, 0.7387247278382582, 0.26127527216174184]\n",
      "max_features = 0.8 : [1.0, 0.7091757387247278, 0.29082426127527217]\n",
      "max_features = 0.9 : [1.0, 0.7091757387247278, 0.29082426127527217]\n"
     ]
    }
   ],
   "source": [
    "n_features = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for max_features in n_features:\n",
    "    tree = DecisionTreeClassifier(random_state=88, max_features=max_features)\n",
    "    tree.fit(features_train, target_train)\n",
    "    train_score = tree.score(features_train, target_train)\n",
    "    valid_score = tree.score(features_valid, target_valid)\n",
    "    scores_difference = train_score - valid_score\n",
    "    scores = [train_score, valid_score, scores_difference]\n",
    "    print(\"max_features =\", max_features, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The training set scores are fixed at 1.0, while the validation scores are firstly increase then decrease. We couldn't avoid from the overfitting when we tuned this hyperparameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will analyze the first three hyperparameters combinations while narrowing the scala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3 min_samples_split = 75 min_samples_leaf = 40 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 3 min_samples_split = 75 min_samples_leaf = 45 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 3 min_samples_split = 75 min_samples_leaf = 50 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 3 min_samples_split = 80 min_samples_leaf = 40 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 3 min_samples_split = 80 min_samples_leaf = 45 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 3 min_samples_split = 80 min_samples_leaf = 50 : [0.7930497925311203, 0.8040435458786936, -0.010993753347573354]\n",
      "max_depth = 4 min_samples_split = 75 min_samples_leaf = 40 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 4 min_samples_split = 75 min_samples_leaf = 45 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 4 min_samples_split = 75 min_samples_leaf = 50 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 4 min_samples_split = 80 min_samples_leaf = 40 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 4 min_samples_split = 80 min_samples_leaf = 45 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 4 min_samples_split = 80 min_samples_leaf = 50 : [0.803941908713693, 0.80248833592535, 0.001453572788343016]\n",
      "max_depth = 5 min_samples_split = 75 min_samples_leaf = 40 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 5 min_samples_split = 75 min_samples_leaf = 45 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 5 min_samples_split = 75 min_samples_leaf = 50 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 5 min_samples_split = 80 min_samples_leaf = 40 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 5 min_samples_split = 80 min_samples_leaf = 45 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n",
      "max_depth = 5 min_samples_split = 80 min_samples_leaf = 50 : [0.8189834024896265, 0.7993779160186625, 0.01960548647096405]\n"
     ]
    }
   ],
   "source": [
    "for depth in range(3, 6):\n",
    "    for split in range(75, 81, 5):\n",
    "        for leaf in range(40, 51, 5):\n",
    "            tree = DecisionTreeClassifier(random_state=88, max_depth=depth)\n",
    "            tree.fit(features_train, target_train)\n",
    "            train_score = tree.score(features_train, target_train)\n",
    "            valid_score = tree.score(features_valid, target_valid)\n",
    "            scores_difference = train_score - valid_score\n",
    "            scores = [train_score, valid_score, scores_difference]\n",
    "            hayperparameters = []\n",
    "            (print(\"max_depth =\", depth, \"min_samples_split =\", split, \"min_samples_leaf =\", leaf, \":\", scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We tried many combinations of three hyperparameters and saw there were no differences in results for 'min_samples_split' and 'min_samples_leaf' values when we defined max_depth. So, it's enough to select '4' for the 'max_depth' hyperparameter as we saw in the first for loop. Other parameters had no effect when we defined the max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(random_state=88, max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.803941908713693"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = tree.score(features_train, target_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80248833592535"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = tree.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores are higher than the project requirement (0.75) and fitting of the model is optimum when we compare the valid score and training score.\n",
    "- Let's use Grid Search and Random Search Optimisation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the GridSearchCV from model_selection modul."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the ranges of hyperparameters to find the best score using these hyperparameters. We will create a dictionary from them to set parameters of grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = range(3,8)\n",
    "min_samples_split = range(75, 81, 2)\n",
    "min_samples_leaf = range(40, 51, 2)\n",
    "splitter = [\"best\", \"random\"]\n",
    "presort = [True, False]\n",
    "\n",
    "param_grid = (dict(max_depth=max_depth, min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf, \n",
    "                   splitter=splitter, presort=presort))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import the time module to evaluate the searching time. We will find the seraching times and compare the time of Grid Search to time of Random Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.763608 using {'max_depth': 3, 'min_samples_leaf': 40, 'min_samples_split': 75, 'presort': True, 'splitter': 'best'}\n",
      "Best validation: 0.763608 using {'max_depth': 3, 'min_samples_leaf': 40, 'min_samples_split': 75, 'presort': True, 'splitter': 'best'}\n",
      "Execution time: 10.698229312896729 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=88)\n",
    "grid = GridSearchCV(estimator=tree, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(features_train, target_train)\n",
    "validation_grid_result = grid.fit(features_valid, target_valid)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Best validation: %f using %s\" % (validation_grid_result.best_score_, validation_grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will import RandomzedSearchCV and make same steps for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.758942 using {'splitter': 'best', 'presort': False, 'min_samples_split': 77, 'min_samples_leaf': 44, 'max_depth': 7}\n",
      "Best validation: 0.758942 using {'splitter': 'best', 'presort': False, 'min_samples_split': 77, 'min_samples_leaf': 44, 'max_depth': 7}\n",
      "Execution time: 0.3178582191467285 ms\n"
     ]
    }
   ],
   "source": [
    "random = RandomizedSearchCV(estimator=tree, param_distributions=param_grid, cv = 3, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "random_result = random.fit(features_train, target_train)\n",
    "validation_grid_result = random.fit(features_valid, target_valid)\n",
    "\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Best validation: %f using %s\" % (validation_grid_result.best_score_, validation_grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We tried two different search methods to optimize the hyperparameters. We can compare the training results to the validation results.\n",
    "- The scores are lower than our manual tuning, but higher than project requirement (0.75). So, it seems like our manual tuning results are better.\n",
    "- The execution time of Random Search is better than Grid Search's. We will use the hyperparameters of the Grid Search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = (DecisionTreeClassifier(random_state=88, splitter = 'best', presort = True, \n",
    "                                min_samples_split = 75, min_samples_leaf = 40, max_depth = 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=40, min_samples_split=75,\n",
       "                       min_weight_fraction_leaf=0.0, presort=True,\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7947122861586314"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = tree.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The validation score is above 0.75, nearly 0.80 and the model fitted properly. We can use the hyperparameters which found with the Grid Search method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a model from RandomForestClassifier class. We will do the same steps for Random Forest Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model without Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=88, n_estimators=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9797717842323651"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = forest.score(features_train, target_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7884914463452566"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = forest.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our Random Forest doesn't predict properly. There is also overfitting. Let's go ahead to find the optimum hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators = 1 : [0.8941908713692946, 0.6967340590979783, 0.1974568122713164]\n",
      "n_estimators = 11 : [0.9870331950207469, 0.7916018662519441, 0.19543132876880287]\n",
      "n_estimators = 21 : [0.9963692946058091, 0.7838258164852255, 0.2125434781205836]\n",
      "n_estimators = 31 : [0.9989626556016598, 0.7853810264385692, 0.21358162916309054]\n",
      "n_estimators = 41 : [0.9994813278008299, 0.7931570762052877, 0.20632425159554213]\n",
      "n_estimators = 51 : [0.9989626556016598, 0.7931570762052877, 0.205805579396372]\n",
      "n_estimators = 61 : [0.9994813278008299, 0.7931570762052877, 0.20632425159554213]\n",
      "n_estimators = 71 : [1.0, 0.7853810264385692, 0.21461897356143078]\n",
      "n_estimators = 81 : [1.0, 0.7900466562986003, 0.20995334370139973]\n",
      "n_estimators = 91 : [1.0, 0.7916018662519441, 0.20839813374805594]\n",
      "n_estimators = 101 : [1.0, 0.7853810264385692, 0.21461897356143078]\n"
     ]
    }
   ],
   "source": [
    "for n_estim in range(1, 110, 10):\n",
    "    forest = RandomForestClassifier(random_state=88, n_estimators=n_estim)\n",
    "    forest.fit(features_train, target_train)\n",
    "    train_score = forest.score(features_train, target_train)\n",
    "    valid_score = forest.score(features_valid, target_valid)\n",
    "    scores_difference = train_score - valid_score\n",
    "    scores = [train_score, valid_score, scores_difference]\n",
    "    print(\"n_estimators =\", n_estim, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores increase while the n_estim values increase, but the scores' differences are bigger when we compared them to our first DecisionTreeClassifier model. The model is not fitted properly. The training results are good, but results of validation set are too lower, especially for higher n_estim values, the model couldn't predict properly for validation set. We can say there is overfitting in our Random Forest model. We will keep to analyze this algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3 n_estimators = 30 : [0.7940871369294605, 0.7978227060653188, -0.0037355691358582632]\n",
      "max_depth = 3 n_estimators = 40 : [0.7940871369294605, 0.7978227060653188, -0.0037355691358582632]\n",
      "max_depth = 3 n_estimators = 50 : [0.7935684647302904, 0.7993779160186625, -0.0058094512883720695]\n",
      "max_depth = 3 n_estimators = 60 : [0.7935684647302904, 0.7993779160186625, -0.0058094512883720695]\n",
      "max_depth = 3 n_estimators = 70 : [0.7930497925311203, 0.7993779160186625, -0.006328123487542192]\n",
      "max_depth = 3 n_estimators = 80 : [0.7940871369294605, 0.7993779160186625, -0.005290779089201947]\n",
      "max_depth = 3 n_estimators = 90 : [0.7940871369294605, 0.7993779160186625, -0.005290779089201947]\n",
      "max_depth = 4 n_estimators = 30 : [0.8065352697095436, 0.7962674961119751, 0.010267773597568475]\n",
      "max_depth = 4 n_estimators = 40 : [0.8013485477178424, 0.8009331259720062, 0.0004154217458361975]\n",
      "max_depth = 4 n_estimators = 50 : [0.8013485477178424, 0.8040435458786936, -0.0026949981608512807]\n",
      "max_depth = 4 n_estimators = 60 : [0.8054979253112033, 0.7978227060653188, 0.007675219245884546]\n",
      "max_depth = 4 n_estimators = 70 : [0.8060165975103735, 0.7993779160186625, 0.006638681491710985]\n",
      "max_depth = 4 n_estimators = 80 : [0.8091286307053942, 0.7978227060653188, 0.011305924640075404]\n",
      "max_depth = 4 n_estimators = 90 : [0.8075726141078838, 0.80248833592535, 0.0050842781825338745]\n",
      "max_depth = 5 n_estimators = 30 : [0.8153526970954357, 0.8009331259720062, 0.014419571123429509]\n",
      "max_depth = 5 n_estimators = 40 : [0.8153526970954357, 0.8009331259720062, 0.014419571123429509]\n",
      "max_depth = 5 n_estimators = 50 : [0.8137966804979253, 0.80248833592535, 0.011308344572575346]\n",
      "max_depth = 5 n_estimators = 60 : [0.8148340248962656, 0.8009331259720062, 0.013900898924259386]\n",
      "max_depth = 5 n_estimators = 70 : [0.8137966804979253, 0.80248833592535, 0.011308344572575346]\n",
      "max_depth = 5 n_estimators = 80 : [0.8148340248962656, 0.80248833592535, 0.012345688970915591]\n",
      "max_depth = 5 n_estimators = 90 : [0.8148340248962656, 0.80248833592535, 0.012345688970915591]\n",
      "max_depth = 6 n_estimators = 30 : [0.8335062240663901, 0.8009331259720062, 0.03257309809438391]\n",
      "max_depth = 6 n_estimators = 40 : [0.8319502074688797, 0.8087091757387247, 0.023241031730155015]\n",
      "max_depth = 6 n_estimators = 50 : [0.8345435684647303, 0.8118195956454122, 0.02272397281931815]\n",
      "max_depth = 6 n_estimators = 60 : [0.8340248962655602, 0.8087091757387247, 0.025315720526835506]\n",
      "max_depth = 6 n_estimators = 70 : [0.8335062240663901, 0.8055987558320373, 0.02790746823435275]\n",
      "max_depth = 6 n_estimators = 80 : [0.8350622406639004, 0.807153965785381, 0.027908274878519435]\n",
      "max_depth = 6 n_estimators = 90 : [0.8360995850622407, 0.8055987558320373, 0.030500829230203363]\n",
      "max_depth = 7 n_estimators = 30 : [0.8537344398340249, 0.7978227060653188, 0.05591173376870606]\n",
      "max_depth = 7 n_estimators = 40 : [0.8526970954356846, 0.7978227060653188, 0.05487438937036582]\n",
      "max_depth = 7 n_estimators = 50 : [0.8521784232365145, 0.8009331259720062, 0.05124529726450833]\n",
      "max_depth = 7 n_estimators = 60 : [0.8537344398340249, 0.8009331259720062, 0.052801313862018695]\n",
      "max_depth = 7 n_estimators = 70 : [0.8563278008298755, 0.8040435458786936, 0.05228425495118183]\n",
      "max_depth = 7 n_estimators = 80 : [0.8558091286307054, 0.8055987558320373, 0.050210372798668024]\n",
      "max_depth = 7 n_estimators = 90 : [0.8558091286307054, 0.8055987558320373, 0.050210372798668024]\n",
      "max_depth = 8 n_estimators = 30 : [0.8661825726141079, 0.8055987558320373, 0.06058381678207059]\n",
      "max_depth = 8 n_estimators = 40 : [0.8687759336099585, 0.8009331259720062, 0.06784280763795236]\n",
      "max_depth = 8 n_estimators = 50 : [0.8739626556016598, 0.80248833592535, 0.0714743196763098]\n",
      "max_depth = 8 n_estimators = 60 : [0.8734439834024896, 0.8009331259720062, 0.07251085743048347]\n",
      "max_depth = 8 n_estimators = 70 : [0.8739626556016598, 0.8040435458786936, 0.06991910972296611]\n",
      "max_depth = 8 n_estimators = 80 : [0.8739626556016598, 0.8040435458786936, 0.06991910972296611]\n",
      "max_depth = 8 n_estimators = 90 : [0.8734439834024896, 0.8055987558320373, 0.0678452275704523]\n"
     ]
    }
   ],
   "source": [
    "for depth in range(3, 9):\n",
    "    for n_estim in range(30, 95, 10):\n",
    "        model = RandomForestClassifier(random_state=88, n_estimators=n_estim, max_depth=depth)\n",
    "        model.fit(features_train, target_train)\n",
    "        train_score = model.score(features_train, target_train)\n",
    "        valid_score = model.score(features_valid, target_valid)\n",
    "        scores_difference = train_score - valid_score\n",
    "        scores = [train_score, valid_score, scores_difference]\n",
    "        print(\"max_depth =\", depth, \"n_estimators =\", n_estim, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'max_depth=4' and 'n_estim=40' has optimum scores and minimum differences. So, we will find the optimum values for hyperparameters close them in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will narrow the search ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = range(30, 55, 5)\n",
    "max_depth = range(4, 8)\n",
    "\n",
    "param_grid = (dict(n_estimators = n_estimators, max_depth = max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=forest, param_grid=param_grid, cv=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.811820 using {'max_depth': 7, 'n_estimators': 35}\n",
      "Best validation: 0.811820 using {'max_depth': 7, 'n_estimators': 35}\n",
      "Execution time: 11.835724592208862 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "grid_result = grid.fit(features_train, target_train)\n",
    "validation_grid_result = grid.fit(features_valid, target_valid)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Best validation: %f using %s\" % (validation_grid_result.best_score_, validation_grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = RandomizedSearchCV(estimator=forest, param_distributions=param_grid, cv = 3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.811820 using {'n_estimators': 35, 'max_depth': 7}\n",
      "Best validation: 0.811820 using {'n_estimators': 35, 'max_depth': 7}\n",
      "Execution time: 6.219845294952393 ms\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "random_result = random.fit(features_train, target_train)\n",
    "validation_grid_result = random.fit(features_valid, target_valid)\n",
    "\n",
    "print(\"Best: %f using %s\" % (random_result.best_score_, random_result.best_params_))\n",
    "print(\"Best validation: %f using %s\" % (validation_grid_result.best_score_, validation_grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The scores are higher than 0.8\n",
    "- The best results for manual tuning were like that: \n",
    "    - max_depth = 4, n_estimators = 40 : train_score: 0.8013485477178424, valid_score : 0.8009331259720062, difference : 0.0004154217458361975\n",
    "- The scores are higher than our manual tuning for Grid and Random Searches. The results for Grid Search:\n",
    "    - max_depth = 7, n_estimators = 35 : train_score: 0.811820, valid_score : 0.811820\n",
    "- The Grid Search method's execution time is longer than the Random Search Method, it's expected. The best results are belong to Grid Search Method. We will use the hyperparameters of the Grid Search which are better than the Random Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = (RandomForestClassifier(random_state=88, n_estimators=35, max_depth=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=35,\n",
       "                       n_jobs=None, oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8009331259720062"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = forest.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Validation score is close the previous forest results and better than previous Decision Tree model (0.7962674961119751)\n",
    "- There isn't underfitting or overfitting. \n",
    "- The winner is Random Forest Model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will create the Logistic Regression model, we will tune the model manually, and tune with Grid Search method but won't use Random Search method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model without Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=88, solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=88, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7152489626556017"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_score = reg.score(features_train, target_train)\n",
    "train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7060653188180405"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = reg.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Scores are close to each other, but lower than project requirement (0.75). Let's tune hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, we will define 'liblinear' for 'solver' and loop for some C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = liblinear , C = 100 : [0.7152489626556017, 0.7060653188180405, 0.009183643837561206]\n",
      "solver = liblinear , C = 10 : [0.7152489626556017, 0.7060653188180405, 0.009183643837561206]\n",
      "solver = liblinear , C = 1.0 : [0.7152489626556017, 0.7060653188180405, 0.009183643837561206]\n",
      "solver = liblinear , C = 0.1 : [0.7152489626556017, 0.7060653188180405, 0.009183643837561206]\n",
      "solver = liblinear , C = 0.01 : [0.7074688796680498, 0.7091757387247278, -0.0017068590566780006]\n"
     ]
    }
   ],
   "source": [
    "solvers = ['liblinear']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "for solver in solvers:\n",
    "    for c in c_values:\n",
    "        reg = LogisticRegression(random_state=88, solver=solver, C=c)\n",
    "        reg.fit(features_train, target_train)\n",
    "        train_score = reg.score(features_train, target_train)\n",
    "        valid_score = reg.score(features_valid, target_valid)\n",
    "        scores_difference = train_score - valid_score\n",
    "        scores = [train_score, valid_score, scores_difference]\n",
    "        print(\"solver =\", solver, \",\", \"C =\", c, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Models for all other 'c_values' except 0.01 have same scores as model without optimisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver = lbfgs , C = 100 : [0.7406639004149378, 0.7418351477449455, -0.0011712473300077297]\n",
      "solver = lbfgs , C = 10 : [0.7406639004149378, 0.7418351477449455, -0.0011712473300077297]\n",
      "solver = lbfgs , C = 1.0 : [0.7385892116182573, 0.7387247278382582, -0.00013551622000085306]\n",
      "solver = lbfgs , C = 0.1 : [0.7131742738589212, 0.702954898911353, 0.010219374947568194]\n",
      "solver = lbfgs , C = 0.01 : [0.7406639004149378, 0.7418351477449455, -0.0011712473300077297]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "solvers = ['lbfgs']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "for solver in solvers:\n",
    "    for c in c_values:\n",
    "        reg = LogisticRegression(random_state=88, solver=solver, C=c)\n",
    "        reg.fit(features_train, target_train)\n",
    "        train_score = reg.score(features_train, target_train)\n",
    "        valid_score = reg.score(features_valid, target_valid)\n",
    "        scores_difference = train_score - valid_score\n",
    "        scores = [train_score, valid_score, scores_difference]\n",
    "        print(\"solver =\", solver, \",\", \"C =\", c, \":\", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All scores are lower than 0.75. Let's make Grid Search Optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will analyze three hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.755832 using {'solver': 'newton-cg'}\n",
      "Best validation: 0.755832 using {'solver': 'newton-cg'}\n",
      "Execution time: 1.1473138332366943 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(random_state=88)\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "\n",
    "params = dict(solver=solvers)\n",
    "\n",
    "grid = GridSearchCV(estimator=reg, param_grid=params, n_jobs=-1, cv=3, scoring='accuracy', error_score=0)\n",
    "\n",
    "start_time = time.time()\n",
    "grid_result = grid.fit(features_train, target_train)\n",
    "validation_grid_result = grid.fit(features_valid, target_valid)\n",
    "       \n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "print(\"Best validation: %f using %s\" % (validation_grid_result.best_score_, validation_grid_result.best_params_))\n",
    "print(\"Execution time: \" + str((time.time() - start_time)) + ' ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are warnings due to different solver selecting from liblinear. We ignored warnings.\n",
    "- Hyperparameters are {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'} for the best score (0.755832). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=88, solver='newton-cg', penalty='l2', C=00.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=88, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418351477449455"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_score = reg.score(features_valid, target_valid)\n",
    "valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's lower than 0.75 and failed.\n",
    "- The winner is Random Forest Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will create a Random Forest model with the best results from Grid Search optimisation.\n",
    "- We will use the test set to check the quality of the model. We will find the accuracy_score, create the confusion_matrix, and find the f1 score to evaluate 'precision' and 'recall' effects and the quality of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=88, n_estimators=35, max_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=35,\n",
       "                       n_jobs=None, oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = forest.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "reals = target_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions  targets\n",
       "0            0        0\n",
       "1            0        0\n",
       "2            0        1\n",
       "3            0        0\n",
       "4            1        1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "results['predictions'] = preds\n",
    "results['targets'] = reals\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>647.46</td>\n",
       "      <td>57.0</td>\n",
       "      <td>17271.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>532.10</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12403.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>368.87</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2123.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>333.41</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15613.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1016.98</td>\n",
       "      <td>71.0</td>\n",
       "      <td>17787.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used\n",
       "0   94.0   647.46      57.0  17271.53\n",
       "1   70.0   532.10      29.0  12403.26\n",
       "2   55.0   368.87       5.0   2123.81\n",
       "3   41.0   333.41      46.0  15613.81\n",
       "4  164.0  1016.98      71.0  17787.52"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_features = features_test.reset_index(drop=True)\n",
    "pd_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>predictions</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>647.46</td>\n",
       "      <td>57.0</td>\n",
       "      <td>17271.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>532.10</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12403.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>368.87</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2123.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>41.0</td>\n",
       "      <td>333.41</td>\n",
       "      <td>46.0</td>\n",
       "      <td>15613.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>164.0</td>\n",
       "      <td>1016.98</td>\n",
       "      <td>71.0</td>\n",
       "      <td>17787.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>69.0</td>\n",
       "      <td>442.96</td>\n",
       "      <td>99.0</td>\n",
       "      <td>26423.48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>639</td>\n",
       "      <td>38.0</td>\n",
       "      <td>275.47</td>\n",
       "      <td>115.0</td>\n",
       "      <td>22988.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>57.0</td>\n",
       "      <td>462.77</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19672.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>641</td>\n",
       "      <td>51.0</td>\n",
       "      <td>385.97</td>\n",
       "      <td>82.0</td>\n",
       "      <td>23806.66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>100.0</td>\n",
       "      <td>751.82</td>\n",
       "      <td>57.0</td>\n",
       "      <td>19204.32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>643 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     calls  minutes  messages   mb_used  predictions  targets\n",
       "0     94.0   647.46      57.0  17271.53            0        0\n",
       "1     70.0   532.10      29.0  12403.26            0        0\n",
       "2     55.0   368.87       5.0   2123.81            0        1\n",
       "3     41.0   333.41      46.0  15613.81            0        0\n",
       "4    164.0  1016.98      71.0  17787.52            1        1\n",
       "..     ...      ...       ...       ...          ...      ...\n",
       "638   69.0   442.96      99.0  26423.48            0        0\n",
       "639   38.0   275.47     115.0  22988.90            0        1\n",
       "640   57.0   462.77      21.0  19672.24            0        0\n",
       "641   51.0   385.97      82.0  23806.66            0        1\n",
       "642  100.0   751.82      57.0  19204.32            0        0\n",
       "\n",
       "[643 rows x 6 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results = pd_features.join(results)\n",
    "pd_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_results['predictions'].value_counts(normalize=True).plot(kind='barh', grid=True)\n",
    "plt.title(\"\\nTest Predictions Percentages\\n\", size=18);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_results['targets'].value_counts(normalize=True).plot(kind='barh', grid=True)\n",
    "plt.title(\"\\nTest Targets Percentages\\n\", size=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 of 10 classes are ultra in the test predictions, while 3 of 10 classes are ultra in the test targets. There are 0.1 difference ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8242612752721618"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = forest.score(features_test, target_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our accuracy score is 82%. 4 of 5 predictions are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the False Predictions' Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's the reverse of accuracy_score, but we will find them in long way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| false_positive : 15 | false_negative 98 | total_right_predictions : 113  |\n"
     ]
    }
   ],
   "source": [
    "false_positive_predictions = pd_results[(pd_results['predictions'] == 1) & (pd_results['targets'] == 0)]['targets'].count()\n",
    "false_negative_predictions = pd_results[(pd_results['predictions'] == 0) & (pd_results['targets'] == 1)]['targets'].count()\n",
    "wrong_predictions = false_positive_predictions + false_negative_predictions\n",
    "(print(\"| false_positive :\", false_positive_predictions, \n",
    "       \"| false_negative\", false_negative_predictions, \n",
    "       \"| total_right_predictions :\", wrong_predictions, \" |\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17573872472783825"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(results)\n",
    "wrong_predictions_ratio = wrong_predictions / total\n",
    "wrong_predictions_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Almost 1 prediction of 5 is false."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[425,  15],\n",
       "       [ 98, 105]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(target_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 425 observations are predicted as Smart (not Ultra:0), their classes are Smart (0) in real.\n",
    "- 105 observations are predicted as Ultra (1), their classes are Ultra (1) in real.\n",
    "- 98 observations are predicted as Ultra (1), but their classes are Smart (not Ultra:0) in real.\n",
    "- 15 observations are predicted as Smart (not Ultra:0), but their classes are Ultra (1) in real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = forest.predict(features_test)\n",
    "precision = precision_score(target_test, test_preds)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 7 true positive predicitons and 1 false positive predictions in 8 positive predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172413793103449"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = recall_score(target_test, test_preds)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Almost 1 true positive prediction in 2 true predictions. The model predicts accurately half of the true plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65015479876161"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score = f1_score(target_test, test_preds)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We studied the data and took a general look at the features and target.\n",
    "- We splitted the source data into 3 parts with 3 : 1 : 1 ratios for training : validation : test\n",
    "- We studied Decision Tree Classifier, Random Forest Classifier and Logistic Regression models.\n",
    "- We made hyperparameter optimisations manually for each algorithma, used Grid Search and Random Search methods t find the best parameters. We generally selected the Grid Search results.\n",
    "- We decided to select Random Forest Classifier model which accuracy score is the highest (about 80%).\n",
    "- We trained the model with training sets, validated the model scores with validation set and checked the results with test set at the last.\n",
    "- The project requirement was minimum 75% of accuracy score . We used classification metrics to check the model scores. \n",
    "- **The accuracy score is about 82%, precision score is 87,5%, recall score is about 52% and f1 score is 65%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
